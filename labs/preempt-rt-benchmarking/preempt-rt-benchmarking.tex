\subchapter{Lab2: Testing and Benchmarking the system}{}

During this lab, you will:
\begin{itemize}
  \item Use benchmarking tools to measure the latencies of a system
  \item Use stressors to analyze various scenarios
  \item Determine suitable options to further improve latencies
\end{itemize}

\section{Determine the maximum latency}

First, we will need to install some benchmark and analysis tools on our system.

In the Buildroot \code{make menuconfig} interface, enable the following packages:

\begin{itemize}
	\item rt-tests
	\item powertop
	\item perf
	\item stress-ng
	\item iperf3
	\item fping
	\item scheduling utilites from the util-linux package
	\item python3
	\item screen
	\item dropbear
\end{itemize}

You'll also need to enable a few features in the kernel. Run \code{make linux-menuconfig} and select
the following options, located in "Kernel Hacking":

\begin{itemize}
	\item Compile-time checks and compiler options -> Compile the kernel with debug info
	\item Tracers -> Function tracer, Interrupts-off tracer, Preemption off tracer, scheduling latency tracer...
\end{itemize}

Re-build the image, and boot it on the board: \code {make linux-rebuild all}

Let's first start by establishing the baseline latency by simply running \code{cyclictest}:

\begin{bashinput}
cyclictest -p 
\end{bashinput}

The goal of this lab is to try to lower the latency as much as possible while
the system is under various types of loads. This will allow us to get the
best running conditions for our applications.

Some tweaks will really be useful on SMP systems, so don't hesitate to test on
your own machine!

Here's a few leads:

\begin{itemize}
	\item Is the system SMP?
	\item Do we need to isolate our task?
	\item Try changing the scheduling policy
	\item Try changing the scheduling priority
	\item Investigate the various interrupts
	\item Take a look at the cpuidle and cpufreq configuration
	\item Are there any NMIs?
\end{itemize}

Stress the system using several tools:

\begin{itemize}
	\item hackbench
	\item stress-ng
	\item iperf3
	\item fping
\end{itemize}

Some kernel options can also be useful:

\begin{itemize}
	\item \code{CONFIG_TRACE_HWLAT}
\end{itemize}

\section{First analysis}

To get a first idea of the wakeup latencies you can expect on your system, launch
\code{cyclictest} on the target, and take a look at the Max latency. The lower, the
better. You shouldn't get big latency spikes.

By running \code{cyclictest} as is, you will run the benchmark with the default
scheduling policy (\code{SCHED_OTHER}), and without any CPU pinning.

You may not notice huge latencies right away, since the system at that point isn't
doing much. You can try to load the system and see how that affects the latencies

To run cyclictest with a real-time scheduling policy, use the \code{-p <prio>} option.
Cyclictest doesn't play well with the \code{chrt} command, since it will itself re-set
it's own scheduling policy.

Try running \code{cyclictest -p 40} and see if you get better latencies.

\subsection{Network load}

An easy way to introduce some load is to generate some network traffic. This will
generate some interrupts, but also stress the kernel and create some context switches.

First, setup the board's network interface:

\code{ip link set eth0 up}

\code{ip address add 192.168.0.2/24 dev eth0}

Make sure that your computer has its network interface on the same subnet as your
target.

On the board,run the \code{iperf3} server in the background:

\code{iperf3 -s -D}

Re-run your cyclictest benchmark, and start sending traffic to your target. From
you host computer, run \code{iperf3 -c 192.168.0.2}. You should start
seeing the latency rising up.

Try comparing the latencies you get between \code{cyclictest} and \code{cyclictest -p 40}. Do you
still see high latencies while some network traffic is being received? If so, why and how
could we fix this?

\subsection{Scheduling load}

Another way to stress the system without any external source is with the \code{hackbench}
tool, which generates a lot of context switches by exchanging data back and forth between
multiple processes and multiple threads. This benchmark is pretty intense and can bring
an entire system down to a non-responsive state, so launch it with only 10 file-descriptors,
running an infinite amout of loops:

\code{hackbench -f 10 -l -1 &}

With hackbench running in the background, compare the output of \code{cyclictest} and \code{cyclictest -p 40}, the
difference should be pretty impressive.

\section{Analyzing the system configuration}

\subsection{CPU Pinning}

Take a look at how many CPUs are on your system. You can run "htop", or
look in \code{/sys/devices/system/cpu/}. This place is useful since you'll find
lots of ways to manage the CPUs:

\begin{itemize}
	\item in \code{cpuX/cpufreq}, you'll find ways to inspect and control the CPU's frequency
	\item in \code{cpuX/cpuidle}, you'll find ways to inspect and control the CPU's idle states
\end{itemize}

If you have multiple CPU cores, it's a good idea to start by isolating:
\begin{itemize}
	\item Your process
	\item Important interrupts
\end{itemize}

On the contrary, you might want to restrict interrupts to cores that won't affect
you process.

To perform this, use the \code{taskset} command, both for running your process, but
also to change the interrupt CPU affinity.

For cyclictest, you can either run cyclictest with the \code{-a <cpu_num>} option,
or use \code{taskset -c <cpu_num> cyclictest ...}.

Try running hackbench and cyclictest on the same CPU, and then on different CPU and
compare the induced latencies.

\subsection{Interrupt Pinning}

It might be a good idea to make sure that no unexpected interrupts occur on the CPU
you use for your realtime application. To know how many interrupts fire on each CPU
core, take a look at the \code{/proc/interrupts} file:

\code{cat /proc/interrupts}.

After you identify the interrupts that fire (take a look at the \code{ethernet} interrupt
when you generate traffic), you cat change it's CPU affinity by going into \code{/proc/irq/<num>/}.

You can then limit it by echo-ing an integer corresponding to the bitfield of enabled CPUS:

\code{echo 1 > smp_affinity} will limit the interrupt to the CPU 0

\code{echo 3 > smp_affinity} will limit the interrupt to the CPU 0 and 1

Try to limit the ethernet interrupt to one CPU core, and launch \code{cyclictest -p 40} on the
other core. You can see that even when launching cyclictest with a priority lower than
the threaded interrupt's, you don't see any impact of network traffic on the latencies.

\subsection{CPU Isolation}

To go even further, you can completely isolate one CPU from the scheduler's pool,
abd have it only accessible through \code{taskset}. To do so, you need to change
the kernel's commandline, passed by the bootloader. On the STM32MP157 platform,
this is done using the \code{extlinux} infrastructure. You can change the
commandline by editing the \code{/boot/extlinux/extlinux.conf} file:

\code{vi /boot/extlinux/extlinux.conf}

Add the \code{isolcpus=1} to the \code{append} line to isolate CPU 1.

Reboot your target, and run cyclictest on CPU1. What can you notice?

\subsection{Using the Tracing subsystem}

In order to use Ftrace, we need to make sure it is enabled in the kernel
configuration. Using \code{make linux-menuconfig}, go in the "Kernel hacking" section
and enable the following options:

\begin{itemize}
	\item Generic Kernel Debugging Instruments -> Debug Filesystem
	\item Tracers -> Kernel Function Tracer
	\item Tracers -> Kernel Function Profiler
	\item Tracers -> Interrupts-off Latency Tracer
	\item Tracers -> Preemption-off Latency Tracer
	\item Tracers -> Scheduling Latency Tracer
	\item Tracers -> Tracer to detect hardware latencies
\end{itemize}

You can now recompile your kernel and re-generate your full image:

\begin{bashinput}
make linux-rebuild
make
\end{bashinput}

Once you've rebooted your board with ftrace enabled, you'll need to mount the
Tracing Filesystem, that gets automatically mounted in debugfs:

\code{mount -t debugfs debugfs /sys/kernel/debug}

\code{mount -t tracefs nodev /sys/kernel/tracing}

You can now move into the tracing subsystem's main directory:

\code{cd /sys/kernel/debug/tracing}

You can now take a little tour of the files here:

\begin{itemize}
	\item \code{available_tracers}: Lists all tracers you can use. Each tracer
		corresponds to what and how do you want the tracing to occur.
	\item \code{current_tracer}: Write the tracer you want to use in this file
	\item \code{tracing_on}: Write 1 to start tracing, 0 to stop tracing
	\item \code{trace}: The content of the trace buffer after tracing is finished
\end{itemize}

First, try the \code{preemptirqsoff} tracer and start tracing:

\begin{bashinput}
echo preemptirqsoff > current_tracer
echo 1 > tracing_on
sleep 10
echo 0 > tracing_on
cat trace
\end{bashinput}

Give a try to other traces: \code{wakeup_rt}, \code{function}, \code{function_graph},
using various of the stressing methods proposed above. Can you get meaningful information?

\section{Using trace-cmd and kernelshark}

Trace-cmd is a wrapper over the raw silesystem-based interface of ftrace. There
are various ways of using it, either standalone, or by recording the behaviour
of the system during a command.

\subsection{Recording}

To record traces during a command, run trace-cmd with the \code{record} keyword:

\begin{bashinput}
# record a full function_graph trace for the duration of the cyclictest run
trace-cmd record -p function_graph cyclictest -p 80 -D 10

# Display the output
trace-cmd report
\end{bashinput}

Running a recording session will automatically export the generated trace in a
"trace.dat" file, that can be displayed with \code{trace-cmd report} or \code{kernelshark}.

\subsection{Manual tracing}

Another approach is to simply start an ftrace session, without relying on a process's
execution. This is useful in combination with the \code{wakeup_rt}, \code{wakeup}, \code{preemptirqsoff} tracers.

\begin{bashinput}
	# Start a tracing session
	trace-cmd start -p wakeup_rt

	# Stop a tracing session
	trace-cmd stop

	# Display the generated trace
	trace-cmd show

	# Export and clear the trace buffer into trace.dat
	trace-cmd extract

	# Display the extraced trace
	trace-cmd report
\end{bashinput}

This approach also allows you to use \code{cyclictest} in conjunction with \code{ftrace},
since you can start at tracing session with \code{trace-cmd start} and have it
stopped automatically when cyclictest detects a high latency:

\begin{bashinput}
	# Start a tracing session
	trace-cmd start -p function_graph

	# Launch cyclictest with the breaktrace option
	cyclictest -p 80 --breaktrace=2000 --tracemark

	# When the high latency is hit, you can display the trace
	trace-cmd show
\end{bashinput}

\section{Using the osnoise tracer}

The following command is used to generate an histogram of os noises with the 
\code{osnoise} tracer:

\code{osnoise hist -c 1 -P f:49 -d 1m}

The output shoud show a maximum latency around 50 000 microseconds. Why is that?

