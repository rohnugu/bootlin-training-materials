\subchapter
{Kernel debugging}
{Objectives:
  \begin{itemize}
    \item Debugging locks and sleeps mistakes using {\em PROVE\_LOCKING} and {\em
    DEBUG\_ATOMIC\_SLEEP} options.
    \item Find a module memory leak using {\em kmemleak}.
    \item Analyzing an {\em oops}.
    \item Debugging with {\em KGDB}.
    \item Setting up {\em Kexec \& kdump}.
  \end{itemize}
}

\section{Locking and sleeps problems}

\kconfig{CONFIG_PROVE_LOCKING} and \kconfig{CONFIG_DEBUG_ATOMIC_SLEEP} have been
enabled in the provided kernel image.
First, compile the module using the following command line:

\begin{bashinput}
$ cd /home/$USER/debugging-labs/nfsroot/root/locking
$ export CROSS_COMPILE=/home/$USER/debugging-labs/buildroot/output/host/bin/arm-linux-
$ export ARCH=arm
$ export KDIR=/home/$USER/debugging-labs/buildroot/output/build/linux-5.13/
$ make
\end{bashinput}

Load the \code{locking.ko} module and look at the output in dmesg:

\begin{bashinput}
# cd /root/locking
# insmod locking_test.ko
# dmesg
\end{bashinput}

Once analyzed, unload the module. Try to understand and fix all the problems that
have been reported by the \code{lockdep} system.

\section{Kmemleak}

The provided kernel image contains kmemleak but it is disabled by default to
avoid having a large overhead. In order to enable it, reboot and enable it by
adding \code{kmemleak=on} on the command line. Interrupt U-Boot at reboot and
modify the \code{bootargs} variable:

\begin{bashinput}
STM32MP> env edit bootargs
STM32MP> <existing bootargs> kmemleak=on
STM32MP> boot
\end{bashinput}

Then compile the kmemleak test module:

\begin{bashinput}
$ cd /home/$USER/debugging-labs/nfsroot/root/kmemleak
$ export CROSS_COMPILE=/home/$USER/debugging-labs/buildroot/output/host/bin/arm-linux-
$ export ARCH=arm
$ export KDIR=/home/$USER/debugging-labs/buildroot/output/build/linux-5.13/
$ make
\end{bashinput}

On the target, load the \code{kmemleak_test.ko} and trigger an immediate
kmemleak scan using:

\begin{bashinput}
# cd /root/kmemleak
# insmod kmemleak_test.ko
# rmmod kmemleak_test
# echo scan > /sys/kernel/debug/kmemleak
\end{bashinput}

Note that you might need to run the \code{scan} command several times
before it detects a leakage due to memory still containing references to
the leaked pointer. Soon after that, the kernel will report that some leaks
have been identified. Display them and analyze them using:

\begin{bashinput}
# cat /sys/kernel/debug/kmemleak
\end{bashinput}

You will see that the symbols addresses do not make sense. This is due to the
\code{kptr_restrict} configuration which must be change to allow displaying
pointer addresses. To do so, use the following command on the target:

\begin{bashinput}
# sysctl kernel.kptr_restrict=1
\end{bashinput}

You can use \code{addr2line} to identify the location in source code of the
lines that did cause the reports. You may need to substract module loading address:
you can guess the address by taking a look at \code{/proc/modules} while the module
is loaded.

You will also notice other memory leaks that are actually some real memory leaks
that did exist in the 5.13 kernel version!

\section{OOPS analysis}
We noticed that the watchdog command generated a crash on the kernel. In order
to reproduce the crash, run the following command:

\begin{bashinput}
$ watchdog -T 10 -t 5 /dev/watchdog0
\end{bashinput}

Immediatly after executing this commands, you'll see that the kernel will report
an OOPS!

\subsection{Analyzing the crash message}

Analyze the crash message carefully. Knowing that on ARM, the \code{PC}
register contains the location of the instruction being executed, find
in which function does the crash happen, and what the function call
stack is.

Using Elixir (\url{https://elixir.bootlin.com/linux/latest/source}) or the
kernel source code, have a look at the definition of this function. In most
cases, a careful review of the driver source code is enough to understand the
issue. But not in that case!

\subsection{Locating the exact line where the error happens}

Even if you already found out which instruction caused the crash, it's
useful to use information in the crash report.

If you look again, the report tells you at what offset in the function
this happens. We will disassemble the code for this function to understand
exactly where the issue happened.

That is where we need a kernel compiled with \kconfig{CONFIG_DEBUG_INFO}
as we did at the beginning of this lab. This way, the kernel vmlinux file is
compiled with \code{-g} compiler flag, which adds a lot of debugging
information (matching between source code lines and assembly for instance).

Using \code{addr2line}, find the exact source code line were the crash happened.
For that, you can use the following command:

\begin{bashinput}
$ addr2line -e /home/$USER/debugging-labs/buildroot/output/build/linux-5.13/vmlinux
  -a <crash_address>
\end{bashinput}

We can even go a step further and use \code{gdb-multiarch} to open vmlinux and
locate the function and corresponding offset in assembly

\begin{bashinput}
$ gdb-multiarch /home/$USER/debugging-labs/buildroot/output/build/linux-5.13/vmlinux
(gdb) disassemble <function>
\end{bashinput}

This can also be done automatically using \code{decode_stacktrace.sh}. First,
copy/paste the OOPS message into the \code{~/debugging-labs/oops.txt} file.
Then, using the script provided by the kernel, execute the following command:

\begin{bashinput}
$ cd /home/$USER/debugging-labs/buildroot/output/build/linux-5.13/
$ export ARCH=arm
$ export CROSS_COMPILE=/home/$USER/debugging-labs/buildroot/output/host/bin/arm-linux-
$ ./scripts/decode_stacktrace.sh vmlinux < ~/debugging-labs/oops.txt
\end{bashinput}

\section{KGDB debugging}
In order to debug this OOPS, we'll use KGDB which is an in-kernel debugger.
The provided image already contains the necessary KGDB support and the watchdog
has been disabled to avoid rebooting while debugging. In order to use KGDB and
the console simultaneously, compile and run kdmx:

\begin{bashinput}
$ git clone https://git.kernel.org/pub/scm/utils/kernel/kgdb/agent-proxy.git
$ cd agent-proxy/kdmx
$ make
$ ./kdmx -n -d -p/dev/ttyACM0 -b115200
serial port: /dev/ttyACM0
Initalizing the serial port to 115200 8n1
/dev/pts/7 is slave pty for terminal emulator
/dev/pts/8 is slave pty for gdb

Use <ctrl>C to terminate program
\end{bashinput}

Note: the slave ports number will depend on the run.

\textbf{Important: before using \code{/dev/pts/7} and \code{/dev/pts/8}, the
picocom process that did opened \code{/dev/ttyACM0} must be closed!}

On the target, setup KGDB by setting the console to be used for that purpose in
kgdboc module parameters:

\begin{bashinput}
$ echo ttySTM0 > /sys/module/kgdboc/parameters/kgdboc
\end{bashinput}

Once done, trigger the crash by running the watchdog command, the system will
automatically wait for a debugger to be attached. Run \code{gdb-multiarch} and
attach a gdb process to KGDB with the following command:

\begin{bashinput}
$ gdb-multiarch /home/$USER/debugging-labs/buildroot/output/build/linux-5.13/vmlinux
(gdb) target remote /dev/pts/8
\end{bashinput}

{\em TIP: in order to allow auto-loading of python scripts, you can add
\code{set auto-load safe-path /} in your .gdbinit file}

First of all, confirm the previous information that were obtain post crash using
GDB. This will allow you to also display variables values. Starting from that
point, we will add a breakpoint on the \code{watchdog_set_drvdata()} function.
However, this function is called early in boot so we will need to actually
attach with KGDB at boot time. To do so, we'll modify the bootargs to specify
that. In U-Boot, add the following arguments to bootargs using \code{env edit}:

\begin{bashinput}
STM32MP> env edit bootargs
STM32MP> <existing bootargs> kgdboc=ttySTM0,115200 kgdbwait
STM32MP> boot
\end{bashinput}

Then the kernel will halt during boot waiting for a GDB process to be attached.
Attached using the same command that was previously used:

\begin{bashinput}
$ gdb-multiarch /home/$USER/debugging-labs/buildroot/output/build/linux-5.13/vmlinux
(gdb) target remote /dev/pts/8
\end{bashinput}

Note: if you do not specify a file to be used, gdb-multiarch won't be able to
detect the architecture automatically and the target command will fail. In that
case, you can set the architecture using:

\begin{bashinput}
(gdb) set arch arm
(gdb) set gnutarget elf32-littlearm
\end{bashinput}

Before continuing the execution, add a breakpoint on
\code{watchdog_set_drvdata()} using the \code{break} GDB command and then
continue the execution using the continue \code{command}

\begin{bashinput}
(gdb) break watchdog_set_drvdata
(gdb) continue
\end{bashinput}

Analyze the subsequent calls and find the place where the driver data are
clobbered.

TIP: you can fix the problem in "live" by modifying the content of the
\code{wdd->driver_data} variable directly using the following command:

\begin{bashinput}
(gdb) p/x var=hex_value
\end{bashinput}

Use it to set the variable with the previous value that was used before getting
clobbered with NULL. Once done, continue the execution and verify that you fixed
the problem using the \code{watchdog} command.

{\em Note: In theory, we could have add a watchpoint to watch the address that
was modified but the arm32 platforms do not provide watchpoints support with
KGDB.}

\subsection{Debugging a module}

KGDB also allows to debug modules and thanks to the GDB python scripts
(\code{lx-symbols}) mainly, it is as easy as debugging kernel core code. In
order to test that feature, we are going to compile a test module and break on
it.

\begin{bashinput}
$ cd /home/$USER/debugging-labs/nfsroot/root/kgdb
$ export CROSS_COMPILE=/home/$USER/debugging-labs/buildroot/output/host/bin/arm-linux-
$ export ARCH=arm
$ export KDIR=/home/$USER/debugging-labs/buildroot/output/build/linux-5.13/
$ make
\end{bashinput}

Then on the target, insert the module using insmod:
\begin{bashinput}
# cd /root/kgdb
# insmod kgdb_test.ko
\end{bashinput}

We can now enter KGDB mode and attach the external gdb to it. We will do
that using using the magic SySrq 'g' key. Before that, ensure the tty
device for gdb already set, or set it now:

\begin{bashinput}
# echo ttySTM0 > /sys/module/kgdboc/parameters/kgdboc
# echo g > /proc/sysrq-trigger
\end{bashinput}

The kernel will then enter KGDB mode and will wait for a gdb connection. On the
development platform, start it and attach to the target:

\begin{bashinput}$
$ gdb-multiarch /home/$USER/debugging-labs/buildroot/output/build/linux-5.13/vmlinux
(gdb) target remote /dev/pts/8
\end{bashinput}

Then you will need to execute the \code{lx-symbols} command in gdb to reload the
symbols from the module. You'll also need to pass a list of path that contains
the external modules:

\begin{bashinput}
(gdb) lx-symbols /home/<user>/debugging-labs/nfsroot/root/kgdb_test/
loading vmlinux
scanning for modules in /home/<user>/debugging-labs/nfsroot/root
loading @0xbf000000: /home/<user>/debugging-labs/nfsroot/root/kgdb_test/kgdb_test.ko
\end{bashinput}

{\em NOTE: If KGDB was already connected and the lx scripts were loaded, then
\code{lx-symbols} will be run automatically on module loading.}

Finally, add a breakpoint right after the \code{pr_debug()} call and continue
the execution to trigger it:

\begin{bashinput}
(gdb) break kgdb_test.c:17
(gdb) continue
\end{bashinput}

At some point, the breakpoint will be triggered. Try to display the variable
\code{i} to display the current loop value.

Note: Due to a GDB bug, sometimes, gdb will crash when continuing. You can
use a temporary breakpoint using the gdb \code{tbreak} command to workaround
this problem.

Bonus: as a side quest you can try to enable the \code{pr_debug()} call using
the dynamic debug feature of the kernel. This can be done using the
\code{/sys/kernel/debug/dynamic_debug/control} file.

\section{kdump \& kexec}

As presented in the course, kdump/kexec allows to boot a new kernel and dump a
perfect copy of the crashed kernel (memory, registers, etc) which can be then
debugged using gdb or crash. 

\subsection{Building the dump-capture kernel}

We will now build the dump-capture kernel which will be booted on crash using
kexec. For that, we will use a simple buildroot image with a builtin initramfs
using the following commands:

\begin{bashinput}
$ cd /home/$USER/debugging-labs/buildroot
$ make O=build_kexec stm32mp157a_dk1_debugging_kexec_defconfig
$ make O=build_kexec
\end{bashinput}

Then, we'll copy the zImage and the device-tree to the nfs /root/kexec
directory:

\begin{bashinput}
$ mkdir /home/$USER/debugging-labs/nfsroot/root/kexec
$ cp images/zImage /home/$USER/debugging-labs/nfsroot/root/kexec
$ cp images/stm32mp157a-dk1.dtb /home/$USER/debugging-labs/nfsroot/root/kexec
\end{bashinput}

These files are now ready to be used from the target using kexec.

\subsection{Configuring kexec}

First of all we need to setup a kexec suitable memory zone for our crash kernel
image. This is achieved via the linux command line. Reboot, interrupt U-Boot and
add the \code{crashkernel=60M} parameter. This will tell the kernel to reserve
60M of memory to load a "rescue" kernel that will be booted on panic. We will
also add an option which will panic the kernel on oops to allow executing the
kexec kernel.

\begin{bashinput}
STM32MP> env edit bootargs
STM32MP> <existing bootargs> crashkernel=60M oops=panic
STM32MP> boot
\end{bashinput}

To load the crash kernel into the previously reserved memory zone, run the
following command:

\begin{bashinput}
# kexec --type zImage -p /root/kexec/zImage --dtb=/root/kexec/stm32mp157a-dk1.dtb
  --command-line="console=ttySTM0,115200n8 maxcpus=1 reset_devices"
\end{bashinput}

Once done, you can trigger a crash using the previously mentioned watchdog
command:

\begin{bashinput}
$ watchdog -T 10 -t 5 /dev/watchdog0
\end{bashinput}

At this moment, the kernel will reboot into a new kernel using the specified
kernel after displaying the backtrace and a message:

\begin{bashinput}
[ 1181.987971] Loading crashdump kernel...
[ 1181.990839] Bye!
\end{bashinput}

After reboot, log into the new kernel normally and bring up the eth0 interface:
(We will use 192.168.0.101 to avoid cloberring ssh \code{know_hosts} file for
the 192.168.0.100 entry).
\begin{bashinput}
$ ifconfig eth0 192.168.0.101
\end{bashinput}

{\textbf Note: ethernet setup might timeout due to some init issues after kexec
boot so this commands needs to be run another time.}

\begin{bashinput}
$ cd /home/$USER/debugging-labs/
$ scp root@192.168.0.101:/proc/vmcore .
\end{bashinput}

Finally, we will be able to debug that kernel coredump using crash.
Using gdb, you can load the \code{vmcore} file using \code{gdb-multiarch}:

\begin{bashinput}
$ gdb-multiarch /home/$USER/debugging-labs/buildroot/output/build/linux-5.13/vmlinux \
  vmcore
\end{bashinput}